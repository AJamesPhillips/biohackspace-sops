#!/usr/bin/python

import os
pw = os.environ['BIOBOT_PW']

from wikitools import wiki
from wikitools import api
from wikitools import category
from wikitools import page

# create a Wiki object
site = wiki.Wiki("https://wiki.london.hackspace.org.uk/w/api.php")
# login - required for read-restricted wikis
login = site.login("biobot", pw)


#bio01001 bio02001 bio03001 bio04001 bio04002 bio04003 bio04004 bio04005 bio04006 bio04007 bio04008 bio05001 bio06001 bio07001 bio07002 bio07003 bio07004 bio07005 bio08001 bio08002 bio08003
for content in ['bio08001']:

  #this is the content, should have already been generated by Makefile
  pagetext = open("mwiki/"+content.lower()+".wiki").read()

  #get page from api.php
  page = page.Page(site, content.upper())

  # try an edit, this will fail with captcha
  myedit = page.edit(text=pagetext, bot=1, summary='Sync from github', answer="Hackney Road")

  print(repr(myedit))

  # this is the edit session token
  print(page.getToken('edit'))

  if myedit['edit']['result'] == 'Failure':
    id=myedit['edit']['captcha']['id']

    # provide the captcha text as query param "answer"
    params = {'action':'edit', 'title':content.upper(),'bot':1,'id':id,'answer':"Hackney Road",'text':pagetext,'token':page.getToken('edit')}
    request = api.APIRequest(site, params)
    # query the API
    result = request.query()
    print(result)


